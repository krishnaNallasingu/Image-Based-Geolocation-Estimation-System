{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vqbtwJcKgq3D"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# import gdown\n",
        "# gdown.download_folder(\"https://drive.google.com/drive/folders/1vtLNqk0N2GriYKcv6FUwiPQHSCBN69E-\", quiet=False, use_cookies=False)\n",
        "\n",
        "\n",
        "# import zipfile\n",
        "# with zipfile.ZipFile(\"/content/Phase_2_data/images_val.zip\", 'r') as zip_ref:\n",
        "#     zip_ref.extractall(\"dataset\")\n",
        "# with zipfile.ZipFile(\"/content/Phase_2_data/images_train.zip\", 'r') as zip_ref:\n",
        "#     zip_ref.extractall(\"dataset\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cOru6Vl7g9Lg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import timm\n",
        "from tqdm import tqdm\n",
        "import torch.cuda.amp as amp\n",
        "\n",
        "# Check for GPU and enable mixed precision\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = True\n",
        "scaler = amp.GradScaler()\n",
        "\n",
        "## Enhanced Data Augmentation\n",
        "def get_train_transform():\n",
        "    return A.Compose([\n",
        "        A.Resize(256, 256),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.1),\n",
        "        A.Rotate(limit=30, p=0.7),\n",
        "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "        A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=20, val_shift_limit=20, p=0.5),\n",
        "        A.CoarseDropout(max_holes=8, max_height=32, max_width=32, fill_value=0, p=0.3),\n",
        "        A.GaussNoise(var_limit=(10.0, 50.0)),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "def get_val_transform():\n",
        "    return A.Compose([\n",
        "        A.Resize(256, 256),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "# Optimized Dataset Class\n",
        "class AngleDataset(Dataset):\n",
        "    def __init__(self, image_dir, labels_csv, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.labels_df = pd.read_csv(labels_csv)\n",
        "        self.labels_df = self.labels_df[self.labels_df['angle'] <= 360]\n",
        "        self.transform = transform\n",
        "        self.samples = [(row['filename'], float(row['angle']))\n",
        "                       for _, row in self.labels_df.iterrows()]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename, angle = self.samples[idx]\n",
        "        img_path = os.path.join(self.image_dir, filename)\n",
        "\n",
        "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "        if image is None:\n",
        "            raise FileNotFoundError(f\"Image not found at {img_path}\")\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Convert angle to sin and cos\n",
        "        sin = np.sin(np.radians(angle))\n",
        "        cos = np.cos(np.radians(angle))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)[\"image\"]\n",
        "\n",
        "        return image, torch.tensor([sin, cos], dtype=torch.float32)\n",
        "\n",
        "# Advanced Model Architecture with Multi-Task Learning\n",
        "class AdvancedAngleRegressor(nn.Module):\n",
        "    def __init__(self, backbone='convnext_large'):\n",
        "        super(AdvancedAngleRegressor, self).__init__()\n",
        "\n",
        "        # Load pretrained backbone from timm\n",
        "        self.backbone = timm.create_model(\n",
        "            backbone,\n",
        "            pretrained=True,\n",
        "            num_classes=0,\n",
        "            features_only=False\n",
        "        )\n",
        "        in_features = self.backbone.num_features\n",
        "\n",
        "        # Freeze first 60% of layers\n",
        "        total_layers = len(list(self.backbone.parameters()))\n",
        "        for i, param in enumerate(self.backbone.parameters()):\n",
        "            if i < total_layers * 0.6:\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # Multi-task learning heads\n",
        "        self.angle_head = nn.Sequential(\n",
        "            nn.Linear(in_features, 2048),\n",
        "            nn.BatchNorm1d(2048),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 2)  # sin and cos\n",
        "        )\n",
        "\n",
        "        # Auxiliary classification head (cardinal directions)\n",
        "        self.aux_head = nn.Sequential(\n",
        "            nn.Linear(in_features, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(1024, 8)  # 8 cardinal directions\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x)\n",
        "        angle_output = self.angle_head(features)\n",
        "        aux_output = self.aux_head(features)\n",
        "        return angle_output, aux_output\n",
        "\n",
        "# Enhanced Loss Function\n",
        "class CombinedLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.2):\n",
        "        super(CombinedLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, angle_output, aux_output, angle_target, aux_target):\n",
        "        # Circular regression loss\n",
        "        circ_loss = 1 - torch.mean(torch.sum(angle_output * angle_target, dim=1))\n",
        "\n",
        "        # Auxiliary classification loss\n",
        "        aux_loss = nn.CrossEntropyLoss()(aux_output, aux_target)\n",
        "\n",
        "        return circ_loss + self.alpha * aux_loss\n",
        "\n",
        "# Mean Absolute Angular Error\n",
        "def mean_angular_error(preds, targets):\n",
        "    pred_angles = torch.atan2(preds[:, 0], preds[:, 1]) * 180 / np.pi\n",
        "    target_angles = torch.atan2(targets[:, 0], targets[:, 1]) * 180 / np.pi\n",
        "    diff = torch.abs(pred_angles - target_angles)\n",
        "    return torch.mean(torch.min(diff, 360 - diff))\n",
        "\n",
        "# Training function with mixed precision\n",
        "def train_model(model, train_loader, val_loader, epochs=30):\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-5)\n",
        "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=1e-6)\n",
        "    criterion = CombinedLoss(alpha=0.2)\n",
        "    best_maae = float('inf')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
        "        for images, angle_targets in pbar:\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            angle_targets = angle_targets.to(device, non_blocking=True)\n",
        "\n",
        "            # Create auxiliary targets (cardinal directions)\n",
        "            angles = torch.atan2(angle_targets[:, 0], angle_targets[:, 1]) * 180 / np.pi\n",
        "            aux_targets = ((angles + 360) % 360 / 45).long() % 8\n",
        "            aux_targets = aux_targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Mixed precision training\n",
        "            with amp.autocast():\n",
        "                angle_output, aux_output = model(images)\n",
        "                loss = criterion(angle_output, aux_output, angle_targets, aux_targets)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "        # Validation with TTA\n",
        "        model.eval()\n",
        "        val_preds = []\n",
        "        val_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, targets in val_loader:\n",
        "                images = images.to(device, non_blocking=True)\n",
        "                targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "                # Base prediction\n",
        "                angle_output, _ = model(images)\n",
        "\n",
        "                # TTA - horizontal flip\n",
        "                flipped_images = torch.flip(images, dims=[3])\n",
        "                flipped_output, _ = model(flipped_images)\n",
        "\n",
        "                # Average predictions\n",
        "                combined_output = (angle_output + flipped_output) / 2\n",
        "\n",
        "                val_preds.append(combined_output.cpu())\n",
        "                val_targets.append(targets.cpu())\n",
        "\n",
        "        val_preds = torch.cat(val_preds)\n",
        "        val_targets = torch.cat(val_targets)\n",
        "\n",
        "        maae = mean_angular_error(val_preds, val_targets).item()\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {running_loss/len(train_loader):.4f} | Val MAAE: {maae:.2f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if maae < best_maae:\n",
        "            best_maae = maae\n",
        "            torch.save(model.state_dict(), 'best_model_Angle.pth')\n",
        "            print(f\"New best MAAE: {best_maae:.2f}\")\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = AngleDataset(\"/content/dataset/images_train\", \"/content/Phase_2_data/labels_train.csv\", get_train_transform())\n",
        "val_dataset = AngleDataset(\"/content/dataset/images_val\", \"/content/Phase_2_data/labels_val.csv\", get_val_transform())\n",
        "\n",
        "# Optimized DataLoader settings\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,\n",
        "                         num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False,\n",
        "                       num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "# Initialize and train model\n",
        "model = AdvancedAngleRegressor(backbone='convnext_large').to(device)\n",
        "train_model(model, train_loader, val_loader, epochs=23)\n",
        "\n",
        "#### Works for only Val data the below for 17 epochs got best MAAE 36.69\n",
        "\n",
        "# # Generate predictions with TTA\n",
        "# def predict_with_tta(model, loader):\n",
        "#     model.eval()\n",
        "#     angles = []\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for images, _ in loader:\n",
        "#             images = images.to(device, non_blocking=True)\n",
        "\n",
        "#             # Base prediction\n",
        "#             angle_output, _ = model(images)\n",
        "\n",
        "#             # TTA - horizontal flip\n",
        "#             flipped_images = torch.flip(images, dims=[3])\n",
        "#             flipped_output, _ = model(flipped_images)\n",
        "\n",
        "#             # Average predictions\n",
        "#             combined_output = (angle_output + flipped_output) / 2\n",
        "\n",
        "#             # Convert to angles\n",
        "#             batch_angles = torch.atan2(combined_output[:, 0], combined_output[:, 1]) * 180 / np.pi\n",
        "#             batch_angles = (batch_angles + 360) % 360\n",
        "#             angles.extend(batch_angles.cpu().numpy())\n",
        "#             torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "#     return angles\n",
        "\n",
        "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "# predicted_angles = predict_with_tta(model, val_loader)\n",
        "\n",
        "# # Create submission\n",
        "# submission = pd.DataFrame({\n",
        "#     'id': range(len(predicted_angles)),\n",
        "#     'angle': predicted_angles\n",
        "# })\n",
        "\n",
        "# # Add dummy test predictions\n",
        "# dummy_test = pd.DataFrame({\n",
        "#     'id': range(len(predicted_angles), 738),\n",
        "#     'angle': [0] * (738 - len(predicted_angles))\n",
        "# })\n",
        "\n",
        "# submission = pd.concat([submission, dummy_test], ignore_index=True)\n",
        "# submission.to_csv(\"2022101002_best_angle.csv\", index=False)\n",
        "# print(\"Best submission file saved: 2022101002_best_angle.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOqB_X5aJZLU"
      },
      "outputs": [],
      "source": [
        "\n",
        "#### works fine for both Test + Val and correct Output Format\n",
        "\n",
        "\n",
        "# Generate predictions with TTA\n",
        "def predict_with_tta(model, loader):\n",
        "    model.eval()\n",
        "    angles = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, _ in loader:\n",
        "            images = images.to(device, non_blocking=True)\n",
        "\n",
        "            # Base prediction\n",
        "            angle_output, _ = model(images)\n",
        "\n",
        "            # TTA - horizontal flip\n",
        "            flipped_images = torch.flip(images, dims=[3])\n",
        "            flipped_output, _ = model(flipped_images)\n",
        "\n",
        "            # Average predictions\n",
        "            combined_output = (angle_output + flipped_output) / 2\n",
        "\n",
        "            # Convert to angles\n",
        "            batch_angles = torch.atan2(combined_output[:, 0], combined_output[:, 1]) * 180 / np.pi\n",
        "            batch_angles = (batch_angles + 360) % 360\n",
        "            angles.extend(batch_angles.cpu().numpy())\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    return angles\n",
        "\n",
        "# Create test dataset class (without labels)\n",
        "class TestAngleDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = sorted(os.listdir(image_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.image_files[idx]\n",
        "        img_path = os.path.join(self.image_dir, filename)\n",
        "\n",
        "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "        if image is None:\n",
        "            raise FileNotFoundError(f\"Image not found at {img_path}\")\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)[\"image\"]\n",
        "\n",
        "        return image, filename  # Return filename for identification\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load('/content/best_model_Angle.pth'))\n",
        "model.to(device)\n",
        "\n",
        "# Predict on validation set (369 images)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "val_predicted_angles = predict_with_tta(model, val_loader)\n",
        "\n",
        "# Predict on test set (369 images)\n",
        "test_dataset = TestAngleDataset(\"/content/drive/MyDrive/images_test\", get_val_transform())\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "test_predicted_angles = predict_with_tta(model, test_loader)\n",
        "\n",
        "# Combine predictions (val first, then test)\n",
        "all_predictions = val_predicted_angles + test_predicted_angles\n",
        "\n",
        "# Create submission DataFrame with IDs 0-737\n",
        "submission = pd.DataFrame({\n",
        "    'id': range(738),  # 0 to 737\n",
        "    'angle': all_predictions\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "submission.to_csv(\"2022101002_best_angle_Test_Finalll.csv\", index=False)\n",
        "print(\"Best submission file saved: 2022101002_best_angle.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
