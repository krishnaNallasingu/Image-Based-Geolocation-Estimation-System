{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11675791,"sourceType":"datasetVersion","datasetId":7327932},{"sourceId":11676309,"sourceType":"datasetVersion","datasetId":7328310}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import os\n# import torch\n# from IPython.display import clear_output\n\n# # Clear CUDA memory and cache\n# torch.cuda.empty_cache()\n# clear_output()\n\n# # Verify memory is cleared\n# print(f\"CUDA Memory allocated: {torch.cuda.memory_allocated()/1024**3:.2f}GB (should be 0.00GB)\")\n# print(f\"CUDA Memory reserved: {torch.cuda.memory_reserved()/1024**3:.2f}GB (should be 0.00GB)\")\n\n# # Environment setup\n# os.environ['NO_ALBUMENTATIONS_UPDATE'] = '1'  # Disable Albumentations update warnings\n# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'  # Prevent fragmentation\n# print(\"Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T21:41:17.171677Z","iopub.execute_input":"2025-05-04T21:41:17.172023Z","iopub.status.idle":"2025-05-04T21:41:17.192106Z","shell.execute_reply.started":"2025-05-04T21:41:17.172004Z","shell.execute_reply":"2025-05-04T21:41:17.191610Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"# Model - 1 --> working : True","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.metrics import mean_squared_error\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms\nimport timm\nfrom scipy.stats import zscore\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\nfrom torch.cuda.amp import GradScaler, autocast\nfrom tqdm import tqdm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.preprocessing import RobustScaler\n\n# ---------------------- 1. Configuration ----------------------\nSEED = 42\nBATCH_SIZE =20\nEPOCHS = 43\nEARLY_STOPPING_PATIENCE = 11\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\n\n# ---------------------- 2. Enhanced Data Preparation ----------------------\ndef load_data():\n    train_df = pd.read_csv('/kaggle/input/labels-geo-data-smai/labels_train.csv')\n    val_df = pd.read_csv('/kaggle/input/labels-geo-data-smai/labels_val.csv')\n    \n    train_df['filepath'] = train_df['filename'].apply(lambda x: os.path.join('/kaggle/input/geo-data-final-smai/final_datasets/images_train', x))\n    val_df['filepath'] = val_df['filename'].apply(lambda x: os.path.join('/kaggle/input/geo-data-final-smai/final_datasets/images_val', x))\n    \n    def remove_outliers(df):\n        for col in ['latitude', 'longitude']:\n            Q1 = df[col].quantile(0.25)\n            Q3 = df[col].quantile(0.75)\n            IQR = Q3 - Q1\n            lower_bound = Q1 - 3 * IQR\n            upper_bound = Q3 + 3 * IQR\n            df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n        return df\n    \n    train_df = remove_outliers(train_df)\n    val_df = remove_outliers(val_df)\n    return train_df, val_df\n\ntrain_df, val_df = load_data()\n\n# ---------------------- 3. Advanced Data Augmentation & Normalization ----------------------\nclass GeoDataset(Dataset):\n    def __init__(self, df, transform=None, is_train=False):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n        self.is_train = is_train\n        \n        if 'latitude' in df.columns and 'longitude' in df.columns:\n            self.scaler_lat = RobustScaler()\n            self.scaler_lon = RobustScaler()\n            self.scaler_lat.fit(df[['latitude']].values.reshape(-1, 1))\n            self.scaler_lon.fit(df[['longitude']].values.reshape(-1, 1))\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        image = Image.open(row['filepath']).convert('RGB')\n        image = np.array(image)\n        \n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        \n        if 'latitude' in row and 'longitude' in row:\n            latitude = self.scaler_lat.transform([[row['latitude']]])[0][0]\n            longitude = self.scaler_lon.transform([[row['longitude']]])[0][0]\n            return image, torch.tensor([latitude, longitude], dtype=torch.float32)\n        else:\n            return image, torch.tensor([0, 0], dtype=torch.float32)\n\ntrain_transform = A.Compose([\n    A.Resize(256, 256),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.RandomRotate90(p=0.5),\n    A.Transpose(p=0.5),\n    A.Affine(\n        translate_percent=(-0.1, 0.1),\n        scale=(0.85, 1.15),\n        rotate=(-15, 15),\n        p=0.5\n    ),\n    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n    A.CoarseDropout(\n        max_holes=8,\n        min_holes=1,\n        max_height=32,\n        min_height=8,\n        max_width=32,\n        min_width=8,\n        fill_value=0,\n        mask_fill_value=None,\n        p=0.5\n    ),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ToTensorV2(),\n])\n\nval_transform = A.Compose([\n    A.Resize(256, 256),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ToTensorV2(),\n])\n\ntrain_ds = GeoDataset(train_df, train_transform, is_train=True)\nval_ds = GeoDataset(val_df, val_transform)\n\ntrain_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\nval_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n\n# ---------------------- 4. Enhanced Model Architecture ----------------------\nclass GeoLocalizationModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = timm.create_model('tf_efficientnetv2_m', pretrained=True, num_classes=0)\n        \n        self.attention = nn.Sequential(\n            nn.Linear(1280, 512),\n            nn.SiLU(),\n            nn.Linear(512, 1280),\n            nn.Sigmoid())\n        \n        self.coord_head = nn.Sequential(\n            nn.Linear(1280, 1024),\n            nn.SiLU(),\n            nn.Dropout(0.3),\n            nn.Linear(1024, 512),\n            nn.SiLU(),\n            nn.Dropout(0.2),\n            nn.Linear(512, 2))\n        \n        self._init_weights()\n    \n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        attn_weights = self.attention(features)\n        weighted_features = features * attn_weights\n        coords = self.coord_head(weighted_features)\n        return coords\n\nmodel = GeoLocalizationModel().cuda()\n\n# ---------------------- 5. Enhanced Training Setup ----------------------\noptimizer = torch.optim.AdamW(model.parameters(), lr=5e-3, weight_decay=1e-5)\nscheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\ncriterion = nn.MSELoss()\nscaler = torch.cuda.amp.GradScaler()\n\n# ---------------------- 6. Enhanced Training Loop ----------------------\ndef evaluate(model, dataloader, denormalize=True):\n    model.eval()\n    preds, targets = [], []\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images = images.cuda()\n            output = model(images)\n            preds.append(output.cpu().numpy())\n            targets.append(labels.cpu().numpy())\n    \n    preds = np.vstack(preds)\n    targets = np.vstack(targets)\n    \n    if denormalize and hasattr(dataloader.dataset, 'scaler_lat'):\n        preds_lat = dataloader.dataset.scaler_lat.inverse_transform(preds[:, 0].reshape(-1, 1))\n        preds_lon = dataloader.dataset.scaler_lon.inverse_transform(preds[:, 1].reshape(-1, 1))\n        targets_lat = dataloader.dataset.scaler_lat.inverse_transform(targets[:, 0].reshape(-1, 1))\n        targets_lon = dataloader.dataset.scaler_lon.inverse_transform(targets[:, 1].reshape(-1, 1))\n        \n        preds = np.hstack([preds_lat, preds_lon])\n        targets = np.hstack([targets_lat, targets_lon])\n    \n    mse_lat = mean_squared_error(targets[:, 0], preds[:, 0])\n    mse_lon = mean_squared_error(targets[:, 1], preds[:, 1])\n    avg_mse = 0.5 * (mse_lat + mse_lon)\n    \n    return avg_mse, mse_lat, mse_lon, preds, targets\n\nbest_val_mse = float('inf')\npatience_counter = 0\n\nfor epoch in range(EPOCHS):\n    model.train()\n    running_loss = 0\n    \n    for images, labels in tqdm(train_dl, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n        images, labels = images.cuda(), labels.cuda()\n        \n        optimizer.zero_grad()\n        \n        with autocast():\n            output = model(images)\n            loss = criterion(output, labels)\n        \n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        \n        running_loss += loss.item()\n    \n    scheduler.step()\n    \n    val_avg_mse, val_mse_lat, val_mse_lon, _, _ = evaluate(model, val_dl)\n    \n    print(f\"\\nEpoch {epoch+1}:\")\n    print(f\"Train Loss: {running_loss/len(train_dl):.4f}\")\n    print(f\"Val Avg MSE: {val_avg_mse:.2f} = (Lat MSE: {val_mse_lat:.2f} + Lon MSE: {val_mse_lon:.2f})\")\n    \n    if val_avg_mse < best_val_mse:\n        best_val_mse = val_avg_mse\n        patience_counter = 0\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'val_mse': val_avg_mse,\n            'epoch': epoch,\n        }, 'best_model_ll_k.pth')\n        print(\"Saved new best model\")\n    else:\n        patience_counter += 1\n        if patience_counter >= EARLY_STOPPING_PATIENCE:\n            print(f\"Early stopping after {epoch+1} epochs\")\n            break\n\n# ---------------------- 7. Load Best Model ----------------------\ncheckpoint = torch.load('best_model_ll_k.pth')\nmodel.load_state_dict(checkpoint['model_state_dict'])\nprint(f\"\\nLoaded best model from epoch {checkpoint['epoch']+1} with Val MSE: {checkpoint['val_mse']:.2f}\")\n\n# ---------------------- 8. Prepare Test Data ----------------------\ntest_images = sorted(os.listdir('/kaggle/input/geo-data-final-smai/final_datasets/images_test'))\ntest_df = pd.DataFrame({\n    'filename': test_images,\n    'filepath': [os.path.join('/kaggle/input/geo-data-final-smai/final_datasets/images_test', img) for img in test_images]\n})\n\ntest_ds = GeoDataset(test_df, val_transform)\ntest_ds.scaler_lat = train_ds.scaler_lat\ntest_ds.scaler_lon = train_ds.scaler_lon\ntest_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n\n# ---------------------- 9. Generate Predictions ----------------------\n# Predict on validation set\n_, _, _, val_preds, val_targets = evaluate(model, val_dl)\n\n# Predict on test set\nmodel.eval()\ntest_preds = []\nwith torch.no_grad():\n    for images, _ in test_dl:\n        images = images.cuda()\n        output = model(images)\n        output = output.cpu().numpy()\n        output_lat = test_ds.scaler_lat.inverse_transform(output[:, 0].reshape(-1, 1))\n        output_lon = test_ds.scaler_lon.inverse_transform(output[:, 1].reshape(-1, 1))\n        test_preds.append(np.hstack([output_lat, output_lon]))\n\ntest_preds = np.vstack(test_preds)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T21:41:17.337977Z","iopub.execute_input":"2025-05-04T21:41:17.338188Z","iopub.status.idle":"2025-05-04T22:42:13.048294Z","shell.execute_reply.started":"2025-05-04T21:41:17.338164Z","shell.execute_reply":"2025-05-04T22:42:13.047510Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_9410/1034464240.py:98: UserWarning: Argument(s) 'max_holes, min_holes, max_height, min_height, max_width, min_width, fill_value, mask_fill_value' are not valid for transform CoarseDropout\n  A.CoarseDropout(\nEpoch 1/43: 100%|██████████| 323/323 [01:21<00:00,  3.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1:\nTrain Loss: 2.5584\nVal Avg MSE: 941872.56 = (Lat MSE: 808172.75 + Lon MSE: 1075572.38)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/43: 100%|██████████| 323/323 [01:20<00:00,  3.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2:\nTrain Loss: 0.4413\nVal Avg MSE: 913621.44 = (Lat MSE: 789858.50 + Lon MSE: 1037384.38)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/43: 100%|██████████| 323/323 [01:20<00:00,  4.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3:\nTrain Loss: 0.4130\nVal Avg MSE: 894713.00 = (Lat MSE: 896595.62 + Lon MSE: 892830.44)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/43: 100%|██████████| 323/323 [01:20<00:00,  4.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4:\nTrain Loss: 0.3898\nVal Avg MSE: 783803.62 = (Lat MSE: 729229.19 + Lon MSE: 838378.00)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/43: 100%|██████████| 323/323 [01:20<00:00,  4.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5:\nTrain Loss: 0.3674\nVal Avg MSE: 720168.50 = (Lat MSE: 633311.81 + Lon MSE: 807025.25)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/43: 100%|██████████| 323/323 [01:20<00:00,  4.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6:\nTrain Loss: 0.3472\nVal Avg MSE: 805537.19 = (Lat MSE: 672450.12 + Lon MSE: 938624.25)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/43: 100%|██████████| 323/323 [01:19<00:00,  4.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7:\nTrain Loss: 0.3316\nVal Avg MSE: 694227.25 = (Lat MSE: 586319.62 + Lon MSE: 802134.81)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/43: 100%|██████████| 323/323 [01:20<00:00,  4.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8:\nTrain Loss: 0.3176\nVal Avg MSE: 628882.50 = (Lat MSE: 556942.44 + Lon MSE: 700822.62)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/43: 100%|██████████| 323/323 [01:20<00:00,  4.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9:\nTrain Loss: 0.3173\nVal Avg MSE: 636501.12 = (Lat MSE: 545363.56 + Lon MSE: 727638.69)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/43: 100%|██████████| 323/323 [01:20<00:00,  4.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10:\nTrain Loss: 0.3135\nVal Avg MSE: 746025.50 = (Lat MSE: 618927.12 + Lon MSE: 873123.81)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/43: 100%|██████████| 323/323 [01:20<00:00,  4.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 11:\nTrain Loss: 0.2969\nVal Avg MSE: 643993.06 = (Lat MSE: 650916.62 + Lon MSE: 637069.50)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/43: 100%|██████████| 323/323 [01:20<00:00,  4.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 12:\nTrain Loss: 0.2898\nVal Avg MSE: 660354.50 = (Lat MSE: 547386.50 + Lon MSE: 773322.44)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/43: 100%|██████████| 323/323 [01:20<00:00,  4.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 13:\nTrain Loss: 0.2775\nVal Avg MSE: 570858.38 = (Lat MSE: 465038.19 + Lon MSE: 676678.56)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/43: 100%|██████████| 323/323 [01:20<00:00,  4.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 14:\nTrain Loss: 0.2719\nVal Avg MSE: 572551.81 = (Lat MSE: 493727.88 + Lon MSE: 651375.75)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/43: 100%|██████████| 323/323 [01:20<00:00,  4.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 15:\nTrain Loss: 0.2642\nVal Avg MSE: 529990.38 = (Lat MSE: 499407.69 + Lon MSE: 560573.06)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/43: 100%|██████████| 323/323 [01:20<00:00,  4.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 16:\nTrain Loss: 0.2567\nVal Avg MSE: 472844.09 = (Lat MSE: 412519.06 + Lon MSE: 533169.12)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/43: 100%|██████████| 323/323 [01:20<00:00,  3.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 17:\nTrain Loss: 0.2486\nVal Avg MSE: 536922.88 = (Lat MSE: 421884.38 + Lon MSE: 651961.44)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/43: 100%|██████████| 323/323 [01:20<00:00,  4.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 18:\nTrain Loss: 0.2494\nVal Avg MSE: 435980.38 = (Lat MSE: 389012.94 + Lon MSE: 482947.81)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/43: 100%|██████████| 323/323 [01:20<00:00,  4.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 19:\nTrain Loss: 0.2349\nVal Avg MSE: 476479.94 = (Lat MSE: 395704.44 + Lon MSE: 557255.44)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/43: 100%|██████████| 323/323 [01:20<00:00,  4.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 20:\nTrain Loss: 0.2304\nVal Avg MSE: 464624.50 = (Lat MSE: 393142.62 + Lon MSE: 536106.38)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/43: 100%|██████████| 323/323 [01:20<00:00,  4.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 21:\nTrain Loss: 0.2189\nVal Avg MSE: 376982.22 = (Lat MSE: 350558.44 + Lon MSE: 403406.00)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/43: 100%|██████████| 323/323 [01:20<00:00,  3.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 22:\nTrain Loss: 0.2121\nVal Avg MSE: 386441.94 = (Lat MSE: 336141.88 + Lon MSE: 436742.00)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/43: 100%|██████████| 323/323 [01:20<00:00,  4.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 23:\nTrain Loss: 0.2077\nVal Avg MSE: 355218.19 = (Lat MSE: 327682.44 + Lon MSE: 382753.91)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/43: 100%|██████████| 323/323 [01:20<00:00,  3.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 24:\nTrain Loss: 0.1942\nVal Avg MSE: 359732.38 = (Lat MSE: 312532.03 + Lon MSE: 406932.69)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/43: 100%|██████████| 323/323 [01:20<00:00,  4.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 25:\nTrain Loss: 0.1816\nVal Avg MSE: 321491.91 = (Lat MSE: 272616.69 + Lon MSE: 370367.12)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/43: 100%|██████████| 323/323 [01:20<00:00,  3.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 26:\nTrain Loss: 0.1698\nVal Avg MSE: 347507.31 = (Lat MSE: 306000.31 + Lon MSE: 389014.28)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/43: 100%|██████████| 323/323 [01:20<00:00,  4.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 27:\nTrain Loss: 0.1714\nVal Avg MSE: 306041.00 = (Lat MSE: 263875.81 + Lon MSE: 348206.19)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/43: 100%|██████████| 323/323 [01:20<00:00,  3.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 28:\nTrain Loss: 0.1517\nVal Avg MSE: 266611.91 = (Lat MSE: 246630.55 + Lon MSE: 286593.25)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/43: 100%|██████████| 323/323 [01:20<00:00,  4.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 29:\nTrain Loss: 0.1437\nVal Avg MSE: 251228.08 = (Lat MSE: 212225.50 + Lon MSE: 290230.66)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/43: 100%|██████████| 323/323 [01:20<00:00,  4.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 30:\nTrain Loss: 0.1339\nVal Avg MSE: 205465.75 = (Lat MSE: 188071.30 + Lon MSE: 222860.20)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31/43: 100%|██████████| 323/323 [01:20<00:00,  4.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 31:\nTrain Loss: 0.1193\nVal Avg MSE: 252411.72 = (Lat MSE: 223854.77 + Lon MSE: 280968.66)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32/43: 100%|██████████| 323/323 [01:21<00:00,  3.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 32:\nTrain Loss: 0.1075\nVal Avg MSE: 208485.19 = (Lat MSE: 183805.30 + Lon MSE: 233165.08)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33/43: 100%|██████████| 323/323 [01:20<00:00,  4.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 33:\nTrain Loss: 0.1011\nVal Avg MSE: 233426.91 = (Lat MSE: 204882.03 + Lon MSE: 261971.80)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34/43: 100%|██████████| 323/323 [01:21<00:00,  3.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 34:\nTrain Loss: 0.0951\nVal Avg MSE: 212848.23 = (Lat MSE: 206939.56 + Lon MSE: 218756.91)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35/43: 100%|██████████| 323/323 [01:20<00:00,  4.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 35:\nTrain Loss: 0.0824\nVal Avg MSE: 189916.91 = (Lat MSE: 164820.17 + Lon MSE: 215013.66)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36/43: 100%|██████████| 323/323 [01:21<00:00,  3.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 36:\nTrain Loss: 0.0735\nVal Avg MSE: 186836.55 = (Lat MSE: 173613.30 + Lon MSE: 200059.80)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 37/43: 100%|██████████| 323/323 [01:20<00:00,  4.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 37:\nTrain Loss: 0.0755\nVal Avg MSE: 177862.64 = (Lat MSE: 141743.83 + Lon MSE: 213981.45)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 38/43: 100%|██████████| 323/323 [01:20<00:00,  4.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 38:\nTrain Loss: 0.0640\nVal Avg MSE: 144958.62 = (Lat MSE: 140024.22 + Lon MSE: 149893.05)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 39/43: 100%|██████████| 323/323 [01:20<00:00,  4.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 39:\nTrain Loss: 0.0605\nVal Avg MSE: 138243.30 = (Lat MSE: 127863.29 + Lon MSE: 148623.31)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 40/43: 100%|██████████| 323/323 [01:20<00:00,  4.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 40:\nTrain Loss: 0.0555\nVal Avg MSE: 131558.47 = (Lat MSE: 119040.93 + Lon MSE: 144076.02)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41/43: 100%|██████████| 323/323 [01:21<00:00,  3.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 41:\nTrain Loss: 0.0544\nVal Avg MSE: 128694.84 = (Lat MSE: 120648.10 + Lon MSE: 136741.59)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 42/43: 100%|██████████| 323/323 [01:20<00:00,  4.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 42:\nTrain Loss: 0.0509\nVal Avg MSE: 124341.77 = (Lat MSE: 114479.22 + Lon MSE: 134204.33)\nSaved new best model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 43/43: 100%|██████████| 323/323 [01:21<00:00,  3.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 43:\nTrain Loss: 0.0503\nVal Avg MSE: 129210.16 = (Lat MSE: 119418.03 + Lon MSE: 139002.30)\n\nLoaded best model from epoch 42 with Val MSE: 124341.77\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# anomaly_ids to skip when assigning IDs\nanomaly_ids = {95, 145, 146, 158, 159, 160, 161}\n\n# Make sure you have 732 predictions\n# all_preds should be of shape (732, 2)\nall_preds = np.vstack([val_preds, test_preds])  # should be (732, 2)\n\nsubmission_data = []\npred_idx = 0  # index for predictions\n\n# Loop over IDs from 0 to 737 (inclusive)\nfor new_id in range(738):\n    if new_id in anomaly_ids:\n        continue  # Skip assigning prediction to this ID\n\n    # Assign prediction to current non-anomalous ID\n    submission_data.append({\n        'id': new_id,\n        'Latitude': int(round(all_preds[pred_idx][0])),\n        'Longitude': int(round(all_preds[pred_idx][1]))\n    })\n    pred_idx += 1  # Move to next prediction\n\n# Final DataFrame\nsubmission = pd.DataFrame(submission_data)\n\n# Sanity checks\nprint(f\"Total IDs: 738\")\nprint(f\"Anomalies skipped: {len(anomaly_ids)}\")\nprint(f\"Predictions used: {pred_idx}\")\nprint(f\"Submission rows: {len(submission)}\")\n\n# Check for duplicate IDs\nif len(submission['id']) != len(submission['id'].unique()):\n    print(\"\\nWarning: Duplicate IDs found\")\nelse:\n    print(\"\\nNo duplicate IDs found\")\n\n# Save to CSV\nsubmission.to_csv('2022101002_31_Lat_Long_k6_ff.csv', index=False)\nprint(\"\\nFinal submission sample (around skipped ID 95):\")\nprint(submission[submission['id'].between(90, 100)])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T23:08:41.262538Z","iopub.execute_input":"2025-05-04T23:08:41.262832Z","iopub.status.idle":"2025-05-04T23:08:41.278283Z","shell.execute_reply.started":"2025-05-04T23:08:41.262811Z","shell.execute_reply":"2025-05-04T23:08:41.277393Z"}},"outputs":[{"name":"stdout","text":"Total IDs: 738\nAnomalies skipped: 7\nPredictions used: 731\nSubmission rows: 731\n\nNo duplicate IDs found\n\nFinal submission sample (around skipped ID 95):\n     id  Latitude  Longitude\n90   90    220335     143744\n91   91    220273     143980\n92   92    220462     143877\n93   93    219829     142008\n94   94    220016     142151\n95   96    219183     141141\n96   97    219335     141383\n97   98    219863     141715\n98   99    218660     143572\n99  100    221226     142910\n","output_type":"stream"}],"execution_count":36}]}