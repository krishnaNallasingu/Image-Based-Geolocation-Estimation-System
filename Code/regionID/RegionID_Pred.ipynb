{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Region ID Prediction - SMAI Mini Project"
      ],
      "metadata": {
        "id": "eEjX_uJGE9e1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import gc\n",
        "# from google.colab import runtime\n",
        "\n",
        "# def clean_gpu():\n",
        "#     # Clear PyTorch cache\n",
        "#     torch.cuda.empty_cache()\n",
        "\n",
        "#     # Force Python garbage collection\n",
        "#     gc.collect()\n",
        "\n",
        "#     # Colab-specific memory release\n",
        "#     try:\n",
        "#         runtime.unassign()\n",
        "#     except:\n",
        "#         pass\n",
        "\n",
        "#     # NVIDIA GPU reset (if available)\n",
        "#     if torch.cuda.is_available():\n",
        "#         torch.cuda.reset_peak_memory_stats()\n",
        "#         torch.cuda.reset_accumulated_memory_stats()\n",
        "#         torch.cuda.ipc_collect()\n",
        "\n",
        "#     # Verify free memory\n",
        "#     free, total = torch.cuda.mem_get_info()\n",
        "#     print(f\"✅ GPU Memory Cleared | Free: {free/1024**3:.2f}GB/{total/1024**3:.2f}GB\")\n",
        "\n",
        "# clean_gpu()  # Execute this before anything else\n"
      ],
      "metadata": {
        "id": "XP7o5fYnd6Gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install efficientnet-pytorch torch-optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGxcVDGYd-23",
        "outputId": "e2a99974-a824-4070-b730-ed85e2528173"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet-pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-optimizer\n",
            "  Downloading torch_optimizer-0.3.0-py3-none-any.whl.metadata (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from efficientnet-pytorch) (2.6.0+cu124)\n",
            "Collecting pytorch-ranger>=0.1.1 (from torch-optimizer)\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl.metadata (509 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->efficientnet-pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->efficientnet-pytorch) (3.0.2)\n",
            "Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m929.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16426 sha256=9c85555a52a15ff9e00cc839d4b75f46c798af386fd1c9f558991792c5466aa5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/6f/9b/231a832f811ab6ebb1b32455b177ffc6b8b1cd8de19de70c09\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-ranger, efficientnet-pytorch, torch-optimizer\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed efficientnet-pytorch-0.7.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-ranger-0.1.1 torch-optimizer-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# import gdown\n",
        "# gdown.download_folder(\"https://drive.google.com/drive/folders/1vtLNqk0N2GriYKcv6FUwiPQHSCBN69E-\", quiet=False, use_cookies=False)\n",
        "\n",
        "\n",
        "# import zipfile\n",
        "# with zipfile.ZipFile(\"/content/Phase_2_data/images_val.zip\", 'r') as zip_ref:\n",
        "#     zip_ref.extractall(\"dataset\")\n",
        "# with zipfile.ZipFile(\"/content/Phase_2_data/images_train.zip\", 'r') as zip_ref:\n",
        "#     zip_ref.extractall(\"dataset\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0Vf_kbKd8bH",
        "outputId": "059bf0a1-c018-421d-95aa-fceed43146c5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1hQrS-2OIDf5ceoSZte48OzNn_znS1VQT images_train.zip\n",
            "Processing file 1aHLzBTGzGeuEoNusam0WZPk9XKitClTV images_val.zip\n",
            "Processing file 1df0A-MN5h1KW_j3B9RqeRvHWWp_iecpg labels_train.csv\n",
            "Processing file 1en9Vq8sM94l09WMyxurAqVzV1VG5UlHV labels_val.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1hQrS-2OIDf5ceoSZte48OzNn_znS1VQT\n",
            "From (redirected): https://drive.google.com/uc?id=1hQrS-2OIDf5ceoSZte48OzNn_znS1VQT&confirm=t&uuid=b5f7d710-3f3c-4ea2-8a6d-89c6b9de5b6c\n",
            "To: /content/Phase_2_data/images_train.zip\n",
            "100%|██████████| 616M/616M [00:04<00:00, 131MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1aHLzBTGzGeuEoNusam0WZPk9XKitClTV\n",
            "From (redirected): https://drive.google.com/uc?id=1aHLzBTGzGeuEoNusam0WZPk9XKitClTV&confirm=t&uuid=9309bbb0-4d80-47c0-95d8-f0e92723f3a3\n",
            "To: /content/Phase_2_data/images_val.zip\n",
            "100%|██████████| 36.2M/36.2M [00:00<00:00, 193MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1df0A-MN5h1KW_j3B9RqeRvHWWp_iecpg\n",
            "To: /content/Phase_2_data/labels_train.csv\n",
            "100%|██████████| 257k/257k [00:00<00:00, 96.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1en9Vq8sM94l09WMyxurAqVzV1VG5UlHV\n",
            "To: /content/Phase_2_data/labels_val.csv\n",
            "100%|██████████| 14.5k/14.5k [00:00<00:00, 39.3MB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WcnNGZ8MdxEt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e74450a-dcd6-4660-a421-c196ab3becce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b5-b6417697.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b5-b6417697.pth\n",
            "100%|██████████| 117M/117M [00:00<00:00, 130MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b5\n",
            "Model compiled with compatible settings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0504 09:56:52.837000 261 torch/_inductor/utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved with val_acc: 0.4065\n",
            "Epoch 1/25 | LR: 1.00e-04 | Train Loss: 2.4779 | Train Acc: 0.2178 | Val Acc: 0.4065 | Best: 0.4065\n",
            "New best model saved with val_acc: 0.6314\n",
            "Epoch 2/25 | LR: 2.00e-04 | Train Loss: 1.8658 | Train Acc: 0.4630 | Val Acc: 0.6314 | Best: 0.6314\n",
            "New best model saved with val_acc: 0.7534\n",
            "Epoch 3/25 | LR: 3.00e-04 | Train Loss: 1.5126 | Train Acc: 0.6068 | Val Acc: 0.7534 | Best: 0.7534\n",
            "New best model saved with val_acc: 0.8076\n",
            "Epoch 4/25 | LR: 4.00e-04 | Train Loss: 1.3181 | Train Acc: 0.6952 | Val Acc: 0.8076 | Best: 0.8076\n",
            "Epoch 5/25 | LR: 5.00e-04 | Train Loss: 1.2155 | Train Acc: 0.7435 | Val Acc: 0.7886 | Best: 0.8076\n",
            "New best model saved with val_acc: 0.8564\n",
            "Epoch 6/25 | LR: 5.00e-04 | Train Loss: 1.0940 | Train Acc: 0.7923 | Val Acc: 0.8564 | Best: 0.8564\n",
            "Epoch 7/25 | LR: 4.97e-04 | Train Loss: 1.0244 | Train Acc: 0.8224 | Val Acc: 0.8238 | Best: 0.8564\n",
            "Epoch 8/25 | LR: 4.90e-04 | Train Loss: 0.9551 | Train Acc: 0.8491 | Val Acc: 0.8482 | Best: 0.8564\n",
            "New best model saved with val_acc: 0.8943\n",
            "Epoch 9/25 | LR: 4.78e-04 | Train Loss: 0.9060 | Train Acc: 0.8675 | Val Acc: 0.8943 | Best: 0.8943\n",
            "New best model saved with val_acc: 0.8970\n",
            "Epoch 10/25 | LR: 4.61e-04 | Train Loss: 0.8452 | Train Acc: 0.8964 | Val Acc: 0.8970 | Best: 0.8970\n",
            "Epoch 11/25 | LR: 4.40e-04 | Train Loss: 0.8250 | Train Acc: 0.9005 | Val Acc: 0.8889 | Best: 0.8970\n",
            "New best model saved with val_acc: 0.9106\n",
            "Epoch 12/25 | LR: 4.15e-04 | Train Loss: 0.7736 | Train Acc: 0.9242 | Val Acc: 0.9106 | Best: 0.9106\n",
            "New best model saved with val_acc: 0.9241\n",
            "Epoch 13/25 | LR: 3.88e-04 | Train Loss: 0.7581 | Train Acc: 0.9326 | Val Acc: 0.9241 | Best: 0.9241\n",
            "Epoch 14/25 | LR: 3.58e-04 | Train Loss: 0.7271 | Train Acc: 0.9444 | Val Acc: 0.9051 | Best: 0.9241\n",
            "Epoch 15/25 | LR: 3.27e-04 | Train Loss: 0.7094 | Train Acc: 0.9471 | Val Acc: 0.9133 | Best: 0.9241\n",
            "Epoch 16/25 | LR: 2.95e-04 | Train Loss: 0.6996 | Train Acc: 0.9509 | Val Acc: 0.9214 | Best: 0.9241\n",
            "New best model saved with val_acc: 0.9404\n",
            "Epoch 17/25 | LR: 2.63e-04 | Train Loss: 0.6737 | Train Acc: 0.9625 | Val Acc: 0.9404 | Best: 0.9404\n",
            "Epoch 18/25 | LR: 2.32e-04 | Train Loss: 0.6671 | Train Acc: 0.9653 | Val Acc: 0.9268 | Best: 0.9404\n",
            "Epoch 19/25 | LR: 2.02e-04 | Train Loss: 0.6588 | Train Acc: 0.9671 | Val Acc: 0.9322 | Best: 0.9404\n",
            "Epoch 20/25 | LR: 1.75e-04 | Train Loss: 0.6519 | Train Acc: 0.9700 | Val Acc: 0.9377 | Best: 0.9404\n",
            "Epoch 21/25 | LR: 1.50e-04 | Train Loss: 0.6430 | Train Acc: 0.9762 | Val Acc: 0.9377 | Best: 0.9404\n",
            "New best model saved with val_acc: 0.9431\n",
            "Epoch 22/25 | LR: 1.29e-04 | Train Loss: 0.6349 | Train Acc: 0.9789 | Val Acc: 0.9431 | Best: 0.9431\n",
            "New best model saved with val_acc: 0.9485\n",
            "Epoch 23/25 | LR: 1.12e-04 | Train Loss: 0.6329 | Train Acc: 0.9772 | Val Acc: 0.9485 | Best: 0.9485\n",
            "New best model saved with val_acc: 0.9512\n",
            "Epoch 24/25 | LR: 1.00e-04 | Train Loss: 0.6253 | Train Acc: 0.9810 | Val Acc: 0.9512 | Best: 0.9512\n",
            "Epoch 25/25 | LR: 9.25e-05 | Train Loss: 0.6187 | Train Acc: 0.9838 | Val Acc: 0.9512 | Best: 0.9512\n",
            "Loaded best model with val accuracy: 0.9512\n",
            "✅ Saved predictions for 369 val + 369 test samples\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "# !pip install efficientnet-pytorch torch-optimizer\n",
        "\n",
        "import os\n",
        "import math\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import warnings\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "NUM_WORKERS = min(4, os.cpu_count() // 2)\n",
        "\n",
        "# ===== Hyperparameters =====\n",
        "# Training Parameters\n",
        "EPOCHS = 25\n",
        "BATCH_SIZE = 28\n",
        "WARMUP_EPOCHS = 5\n",
        "PATIENCE = 10  # Early stopping patience\n",
        "GRADIENT_ACCUMULATION_STEPS = 2\n",
        "\n",
        "# Optimization Parameters\n",
        "INIT_LR = 5e-4\n",
        "MIN_LR = 9e-5\n",
        "WEIGHT_DECAY = 1e-4\n",
        "MAX_GRAD_NORM = 1.0  # Gradient clipping\n",
        "\n",
        "# Model Architecture\n",
        "NUM_FEATURES = 512\n",
        "ATTENTION_DIM = 1024\n",
        "DROPOUT_RATE = 0.5\n",
        "LABEL_SMOOTHING = 0.1\n",
        "UNFREEZE_LAST_N_BLOCKS = 15  # For EfficientNet\n",
        "\n",
        "# Data Augmentation\n",
        "IMAGE_SIZE = 352  # Final crop size\n",
        "INITIAL_RESIZE = 384  # Initial resize before augmentations\n",
        "\n",
        "# AMP Settings\n",
        "if torch.__version__ >= '2.0':\n",
        "    torch.set_float32_matmul_precision('high')\n",
        "\n",
        "scaler = GradScaler()\n",
        "amp_dtype = torch.float16\n",
        "\n",
        "# ===== Data Loading =====\n",
        "train_df = pd.read_csv(\"/content/Phase_2_data/labels_train.csv\")\n",
        "val_df = pd.read_csv(\"/content/Phase_2_data/labels_val.csv\")\n",
        "\n",
        "# Preprocessing\n",
        "for df in [train_df, val_df]:\n",
        "    df['hour'] = df['timestamp'].str.split(\":\").str[0].astype(int)\n",
        "    df['Region_ID'] = df['Region_ID'].astype(int)\n",
        "    df['label'] = df['Region_ID'] - 1  # 0-indexed\n",
        "\n",
        "minmax_scaler = MinMaxScaler()\n",
        "train_tabular = train_df[['latitude', 'longitude', 'angle', 'hour']]\n",
        "val_tabular = val_df[['latitude', 'longitude', 'angle', 'hour']]\n",
        "\n",
        "minmax_scaler.fit(train_tabular)\n",
        "train_df[['latitude', 'longitude', 'angle', 'hour']] = minmax_scaler.transform(train_tabular)\n",
        "val_df[['latitude', 'longitude', 'angle', 'hour']] = minmax_scaler.transform(val_tabular)\n",
        "\n",
        "# ===== Transforms =====\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((INITIAL_RESIZE, INITIAL_RESIZE)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.3),\n",
        "    transforms.RandomAffine(degrees=30, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
        "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.7, 1.0), ratio=(0.8, 1.2)),\n",
        "    transforms.ToTensor(),  # Convert to tensor before tensor-based transforms\n",
        "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.2)),  # Now works with tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((INITIAL_RESIZE, INITIAL_RESIZE)),\n",
        "    transforms.CenterCrop(IMAGE_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# ===== Dataset =====\n",
        "class MultimodalDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        # Load image\n",
        "        img_path = os.path.join(self.img_dir, row['filename'])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Tabular data\n",
        "        tabular = torch.tensor([\n",
        "            float(row['latitude']),\n",
        "            float(row['longitude']),\n",
        "            float(row['angle']),\n",
        "            float(row['hour'])\n",
        "        ], dtype=torch.float32)\n",
        "\n",
        "        label = torch.tensor(row['label'], dtype=torch.long)\n",
        "\n",
        "        return image, tabular, label\n",
        "\n",
        "# ===== Model =====\n",
        "class EfficientNetMultimodal(nn.Module):\n",
        "    def __init__(self, num_classes=15):\n",
        "        super().__init__()\n",
        "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b5')\n",
        "        self.img_feature_dim = 2048\n",
        "\n",
        "        # Freeze/unfreeze layers\n",
        "        for param in self.efficientnet.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in self.efficientnet._blocks[-UNFREEZE_LAST_N_BLOCKS:].parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        self.tabular_net = nn.Sequential(\n",
        "            nn.Linear(4, NUM_FEATURES),\n",
        "            nn.BatchNorm1d(NUM_FEATURES),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(DROPOUT_RATE/2),\n",
        "            nn.Linear(NUM_FEATURES, NUM_FEATURES),\n",
        "            nn.BatchNorm1d(NUM_FEATURES),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(DROPOUT_RATE/2),\n",
        "        )\n",
        "\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(2048 + NUM_FEATURES, ATTENTION_DIM),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(DROPOUT_RATE),\n",
        "            nn.Linear(ATTENTION_DIM, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(2048 + NUM_FEATURES, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(DROPOUT_RATE),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, image, tabular):\n",
        "        img_feat = self.efficientnet.extract_features(image)\n",
        "        img_feat = F.adaptive_avg_pool2d(img_feat, 1).flatten(1)\n",
        "        tab_feat = self.tabular_net(tabular)\n",
        "        combined = torch.cat([img_feat, tab_feat], dim=1)\n",
        "        attn_weights = self.attention(combined)\n",
        "        attended = combined * attn_weights\n",
        "        return self.classifier(attended)\n",
        "\n",
        "# ===== DataLoaders =====\n",
        "train_dataset = MultimodalDataset(train_df, \"/content/dataset/images_train\", train_transform)\n",
        "val_dataset = MultimodalDataset(val_df, \"/content/dataset/images_val\", val_transform)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True if NUM_WORKERS > 0 else False\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True if NUM_WORKERS > 0 else False\n",
        ")\n",
        "\n",
        "# ===== Training Function =====\n",
        "def train_model(model, train_loader, val_loader):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=INIT_LR, weight_decay=WEIGHT_DECAY)\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
        "\n",
        "    # Learning rate scheduler with warmup\n",
        "    def lr_lambda(epoch):\n",
        "        if epoch < WARMUP_EPOCHS:\n",
        "            return (epoch + 1) / WARMUP_EPOCHS\n",
        "        else:\n",
        "            progress = (epoch - WARMUP_EPOCHS) / (EPOCHS - WARMUP_EPOCHS)\n",
        "            return MIN_LR/INIT_LR + 0.5*(1 - MIN_LR/INIT_LR)*(1 + math.cos(math.pi*progress))\n",
        "\n",
        "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    no_improve = 0\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_acc': [], 'lr': []}\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss, total_correct = 0, 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "                # TEST MODE: Break after 5 batches\n",
        "        TEST_MODE = False\n",
        "        batch_counter = 0\n",
        "\n",
        "        for i, (images, tabular, labels) in enumerate(train_loader):\n",
        "            images, tabular, labels = images.to(device), tabular.to(device), labels.to(device)\n",
        "\n",
        "            with autocast(dtype=amp_dtype):\n",
        "                outputs = model(images, tabular)\n",
        "                loss = criterion(outputs, labels) / GRADIENT_ACCUMULATION_STEPS\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if (i + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "                if MAX_GRAD_NORM > 0:\n",
        "                    scaler.unscale_(optimizer)\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            total_loss += loss.item() * images.size(0) * GRADIENT_ACCUMULATION_STEPS\n",
        "            total_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "            # TEST MODE: Break after 5 batches\n",
        "            # batch_counter += 1\n",
        "            # if TEST_MODE and batch_counter >= 5:\n",
        "            #     print(\"\\nTEST MODE: Breaking after 5 batches\")\n",
        "            #     break\n",
        "\n",
        "        # Skip validation in test mode\n",
        "        # if TEST_MODE:\n",
        "            # Save dummy model for prediction testing\n",
        "            # torch.save(model.state_dict(), 'test_model.pth')\n",
        "            # print(\"Saved test model after 5 batches\")\n",
        "            # return None, None  # Return early for testing\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        with torch.no_grad():\n",
        "            for images, tabular, labels in val_loader:\n",
        "                images, tabular, labels = images.to(device), tabular.to(device), labels.to(device)\n",
        "                with autocast(dtype=amp_dtype):\n",
        "                    outputs = model(images, tabular)\n",
        "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        # Calculate metrics\n",
        "        train_loss = total_loss / len(train_loader.dataset)\n",
        "        train_acc = total_correct / len(train_loader.dataset)\n",
        "        val_acc = val_correct / len(val_loader.dataset)\n",
        "\n",
        "        # Update history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['lr'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        scheduler.step()\n",
        "\n",
        "        # Early stopping and model checkpoint\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'best_model_RI_combine.pth')\n",
        "            no_improve = 0\n",
        "            print(f\"New best model saved with val_acc: {best_acc:.4f}\")\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= PATIENCE:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{EPOCHS} | LR: {history['lr'][-1]:.2e} | \"\n",
        "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
        "              f\"Val Acc: {val_acc:.4f} | Best: {best_acc:.4f}\")\n",
        "\n",
        "    # Save training plot\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['train_loss'], label='Train Loss')\n",
        "    plt.title('Training Loss')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['train_acc'], label='Train Acc')\n",
        "    plt.plot(history['val_acc'], label='Val Acc')\n",
        "    plt.title('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.savefig('training_history.png')\n",
        "    plt.close()\n",
        "\n",
        "    return best_acc, history\n",
        "\n",
        "# ===== Test Dataset and Loader =====\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = sorted([f for f in os.listdir(img_dir) if f.endswith('.jpg')])\n",
        "        self.tabular_data = torch.zeros((len(self.image_files), 4), dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.image_files[idx])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, self.tabular_data[idx]\n",
        "\n",
        "# ===== Prediction Function =====\n",
        "def predict_with_tta(model, loader, n_aug=5):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            # Handle both cases: (img, tab) and (img, tab, label)\n",
        "            if len(batch) == 3:\n",
        "                images, tabular, _ = batch  # ignore labels for validation\n",
        "            else:\n",
        "                images, tabular = batch  # test loader only has 2 elements\n",
        "\n",
        "            images, tabular = images.to(device), tabular.to(device)\n",
        "            outputs = torch.zeros((images.size(0), 15), device=device)\n",
        "\n",
        "            for _ in range(n_aug):\n",
        "                with autocast(dtype=amp_dtype):\n",
        "                    aug_imgs = []\n",
        "                    for img in images:\n",
        "                        img_np = img.cpu().numpy().transpose(1, 2, 0)\n",
        "                        img_np = img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "                        img_np = (img_np * 255).astype('uint8')\n",
        "                        aug_img = train_transform(Image.fromarray(img_np))\n",
        "                        aug_imgs.append(aug_img)\n",
        "                    aug_imgs = torch.stack(aug_imgs).to(device)\n",
        "                    outputs += model(aug_imgs, tabular)\n",
        "\n",
        "            all_preds.extend((outputs.argmax(1) + 1).cpu().numpy())\n",
        "    return all_preds\n",
        "\n",
        "\n",
        "\n",
        "# def get_test_images_count(test_dir):\n",
        "#     \"\"\"Verify the exact number of test images\"\"\"\n",
        "#     return len([f for f in os.listdir(test_dir) if f.endswith('.jpg')])\n",
        "\n",
        "# ===== Main Execution =====\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize model\n",
        "    model = EfficientNetMultimodal(num_classes=15)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Compile if available\n",
        "    if torch.__version__ >= '2.0':\n",
        "        try:\n",
        "            model = torch.compile(model, mode='default', fullgraph=False, dynamic=False)\n",
        "            print(\"Model compiled with compatible settings\")\n",
        "        except Exception as e:\n",
        "            print(f\"Compilation failed: {str(e)} - Running uncompiled\")\n",
        "\n",
        "    # Train and select best model based on val accuracy\n",
        "    best_acc, history = train_model(model, train_loader, val_loader)\n",
        "\n",
        "    # Only proceed with prediction if not in TEST MODE\n",
        "    if best_acc is not None:\n",
        "        # Load best model\n",
        "        model.load_state_dict(torch.load('best_model_RI_combine.pth'))\n",
        "        print(f\"Loaded best model with val accuracy: {best_acc:.4f}\")\n",
        "\n",
        "        # Verify test image count\n",
        "        test_dir = \"/content/drive/MyDrive/images_test\"  # Update this path\n",
        "        # test_count = get_test_images_count(test_dir)\n",
        "        # print(f\"Found {test_count} test images\")\n",
        "\n",
        "        # if test_count != 369:\n",
        "        #     print(f\"⚠️ Warning: Expected 369 test images, found {test_count}\")\n",
        "        #     print(\"Listing first 10 files:\")\n",
        "        #     print(os.listdir(test_dir)[:10])\n",
        "\n",
        "        # Create test dataset with exactly 369 samples\n",
        "        class FixedTestDataset(Dataset):\n",
        "            def __init__(self, img_dir, transform=None):\n",
        "                self.img_dir = img_dir\n",
        "                self.transform = transform\n",
        "                # Get all supported image formats (case insensitive)\n",
        "                self.image_files = sorted([\n",
        "                    f for f in os.listdir(img_dir)\n",
        "                    if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "                ])[:369]  # Take first 369 images\n",
        "\n",
        "                # Verify we got enough images\n",
        "                if len(self.image_files) < 369:\n",
        "                    print(f\"Warning: Only found {len(self.image_files)} images in {img_dir}\")\n",
        "                    # Pad with dummy filenames if needed (will raise error if accessed)\n",
        "                    self.image_files.extend([None] * (369 - len(self.image_files)))\n",
        "\n",
        "                self.tabular_data = torch.zeros((369, 4), dtype=torch.float32)\n",
        "\n",
        "            def __len__(self):\n",
        "                return 369  # Always return 369\n",
        "\n",
        "            def __getitem__(self, idx):\n",
        "                if self.image_files[idx] is None:\n",
        "                    raise ValueError(f\"Missing image at index {idx} - only found {len([f for f in self.image_files if f is not None])} real images\")\n",
        "\n",
        "                img_path = os.path.join(self.img_dir, self.image_files[idx])\n",
        "                try:\n",
        "                    image = Image.open(img_path).convert(\"RGB\")\n",
        "                    if self.transform:\n",
        "                        image = self.transform(image)\n",
        "                    return image, self.tabular_data[idx]\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading image {img_path}: {str(e)}\")\n",
        "                    # Return a blank image if there's an error loading\n",
        "                    blank_image = Image.new('RGB', (IMAGE_SIZE, IMAGE_SIZE))\n",
        "                    if self.transform:\n",
        "                        blank_image = self.transform(blank_image)\n",
        "                    return blank_image, self.tabular_data[idx]\n",
        "\n",
        "        # Create loaders\n",
        "        test_dataset = FixedTestDataset(test_dir, val_transform)\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            shuffle=False,\n",
        "            num_workers=NUM_WORKERS\n",
        "        )\n",
        "\n",
        "        # Generate predictions\n",
        "        val_preds = predict_with_tta(model, val_loader)[:369]  # Ensure 369\n",
        "        test_preds = predict_with_tta(model, test_loader)[:369]  # Ensure 369\n",
        "\n",
        "        # Create submission\n",
        "        submission = pd.DataFrame({\n",
        "            'id': list(range(738)),\n",
        "            'Region_ID': val_preds + test_preds\n",
        "        })\n",
        "\n",
        "        # Verify\n",
        "        assert len(submission) == 738, f\"Expected 738, got {len(submission)}\"\n",
        "        submission.to_csv('2022101002_4_RI_combined_xyz.csv', index=False)\n",
        "        print(\"✅ Saved predictions for 369 val + 369 test samples\")\n",
        "    else:\n",
        "        print(\"Test mode completed - skipping prediction phase\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6qMLt1O_d4qK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}